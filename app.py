import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from sklearn.metrics import (
    balanced_accuracy_score, matthews_corrcoef, cohen_kappa_score,
    log_loss, confusion_matrix, classification_report
)
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import warnings
warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="ğŸ¯ ML Metrics Akademisi",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
    }
    .fun-fact {
        background: linear-gradient(45deg, #ff6b6b, #feca57);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
        border-left: 5px solid #ff4757;
    }
    .explanation-box {
        background: #f8f9ff;
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #e1e8ed;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def create_sample_data():
    """Create sample classification data for demonstrations"""
    np.random.seed(42)
    X, y = make_classification(n_samples=1000, n_features=10, n_classes=3, 
                             n_informative=7, n_redundant=2, random_state=42)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # Train a simple model
    clf = RandomForestClassifier(n_estimators=50, random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    y_pred_proba = clf.predict_proba(X_test)
    
    return y_test, y_pred, y_pred_proba

def plot_confusion_matrix(y_true, y_pred, title="Confusion Matrix"):
    """Create an interactive confusion matrix"""
    cm = confusion_matrix(y_true, y_pred)
    
    fig = px.imshow(cm, 
                    labels=dict(x="Tahmin Edilen", y="GerÃ§ek", color="SayÄ±"),
                    x=[f'SÄ±nÄ±f {i}' for i in range(len(cm))],
                    y=[f'SÄ±nÄ±f {i}' for i in range(len(cm))],
                    color_continuous_scale='Blues',
                    title=title)
    
    # Add text annotations
    for i in range(len(cm)):
        for j in range(len(cm[0])):
            fig.add_annotation(x=j, y=i, text=str(cm[i][j]),
                             showarrow=False, font_color="white" if cm[i][j] > cm.max()/2 else "black")
    
    return fig

def homepage():
    """Main homepage with overview"""
    st.markdown('<h1 class="main-header">ğŸ¯ Machine Learning Metrics Akademisi</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="explanation-box">
    <h2>ğŸš€ HoÅŸ Geldiniz!</h2>
    <p>Bu eÄŸlenceli akademide machine learning'in en Ã¶nemli classification metriklerini Ã¶ÄŸreneceksiniz! 
    Her bir metriÄŸi basit Ã¶rnekler, gÃ¶rsel aÃ§Ä±klamalar ve interaktif demonstrasyonlarla keÅŸfedeceÄŸiz.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Overview cards
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
        <h3>ğŸ“Š Accuracy Metrikleri</h3>
        <p>â€¢ Balanced Accuracy<br>
        â€¢ Matthews Correlation Coefficient</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
        <h3>ğŸ¤ Agreement Metrikleri</h3>
        <p>â€¢ Cohen's Kappa<br>
        â€¢ Quadratic Weighted Kappa</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
        <h3>ğŸ“‰ Loss Metrikleri</h3>
        <p>â€¢ Log Loss<br>
        â€¢ Focal Loss</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="fun-fact">
    <h3>ğŸ“ Ã–ÄŸrenme Ä°pucu</h3>
    <p>Sol taraftaki menÃ¼den istediÄŸiniz metriÄŸi seÃ§in ve deep dive yapÄ±n! 
    Her sayfa interaktif Ã¶rnekler ve gÃ¶rsel aÃ§Ä±klamalar iÃ§eriyor.</p>
    </div>
    """, unsafe_allow_html=True)

def balanced_accuracy_page():
    """Balanced Accuracy explanation page"""
    st.markdown("# âš–ï¸ Balanced Accuracy")
    
    st.markdown("""
    <div class="explanation-box">
    <h2>ğŸ¤” Balanced Accuracy Nedir?</h2>
    <p><strong>Basit aÃ§Ä±klama:</strong> Normal accuracy'nin daha adil versiyonu! 
    Ã–zellikle veri setindeki sÄ±nÄ±flar eÅŸit sayÄ±da olmadÄ±ÄŸÄ±nda (imbalanced data) Ã§ok iÅŸe yarar.</p>
    
    <p><strong>GerÃ§ek hayat analojisi:</strong> SÄ±nÄ±fta 90 kÄ±z 10 erkek Ã¶ÄŸrenci var. 
    "Herkesi kÄ±z" diye tahmin etsen doÄŸru olur ama bu adil mi? 
    Balanced Accuracy her sÄ±nÄ±fÄ±n baÅŸarÄ±sÄ±nÄ± eÅŸit aÄŸÄ±rlÄ±kta deÄŸerlendirir!</p>
    """, unsafe_allow_html=True)
    
    st.latex(r'''
    \text{Naive Accuracy} = \frac{90}{100} = 90\% \text{ ama erkekleri hiÃ§ tespit etmiyor!}
    ''')
    
    st.markdown("""
    </div>
    """, unsafe_allow_html=True)
    
    # Formula
    st.markdown("### ğŸ“ FormÃ¼l")
    
    st.latex(r'''
    \text{Balanced Accuracy} = \frac{\text{Sensitivity} + \text{Specificity}}{2}
    ''')
    
    st.latex(r'''
    = \frac{\frac{TP}{TP + FN} + \frac{TN}{TN + FP}}{2}
    ''')
    
    st.markdown("**Alt formÃ¼ller:**")
    
    st.latex(r'''
    \text{Sensitivity (Recall)} = \frac{TP}{TP + FN}
    ''')
    
    st.latex(r'''
    \text{Specificity} = \frac{TN}{TN + FP}
    ''')
    
    st.markdown("""
    **ğŸ§  FormÃ¼lÃ¼n MantÄ±ÄŸÄ±:**
    
    Bu formÃ¼l **her sÄ±nÄ±fÄ±n performansÄ±nÄ± eÅŸit aÄŸÄ±rlÄ±kta** deÄŸerlendirmek iÃ§in tasarlandÄ±:
    
    - **Sensitivity (Recall)** â†’ Pozitif sÄ±nÄ±fÄ±n ne kadarÄ±nÄ± doÄŸru yakaladÄ±k?
    - **Specificity** â†’ Negatif sÄ±nÄ±fÄ±n ne kadarÄ±nÄ± doÄŸru yakaladÄ±k?
    - **Ortalama** â†’ Her iki sÄ±nÄ±fa da eÅŸit saygÄ±!
    """)
    
    st.latex(r'''
    \text{Sensitivity} = \frac{TP}{TP + FN} \quad \text{Specificity} = \frac{TN}{TN + FP}
    ''')
    
    st.markdown("""
    **ğŸ’¡ Neden DoÄŸdu Bu Metrik?**
    Normal accuracy imbalanced data'da yanÄ±ltÄ±cÄ± olur. 100 hastadan 95'i saÄŸlÄ±klÄ±, 5'i hasta olsun. 
    "Herkesi saÄŸlÄ±klÄ±" desen accuracy alÄ±rsÄ±n ama hasta olanlarÄ± hiÃ§ tespit etmemiÅŸsin! 
    Balanced Accuracy bÃ¶yle aldatmacalara kanmaz.
    """)
    
    st.latex(r'''
    \text{Normal Accuracy} = \frac{\text{DoÄŸru Tahminler}}{\text{Toplam Tahminler}} = \frac{95}{100} = 0.95
    ''')
    
    st.markdown("""
    **Ama gerÃ§ekte hasta tespiti:** """)
    
    st.latex(r'''
    \text{Sensitivity} = \frac{0}{5} = 0 \quad \text{(HiÃ§ hasta tespit edilemedi!)}
    ''')
    
    st.markdown("""
    """)
    
    st.markdown("""
    <div style="background: #e8f4f8; padding: 1rem; border-radius: 8px; border-left: 4px solid #2196F3;">
    <strong>ğŸ“š TarihÃ§e:</strong> Bu metrik Ã¶zellikle medical diagnosis ve biyoinformatikte yaygÄ±nlaÅŸtÄ±. 
    Ã‡Ã¼nkÃ¼ hasta olan birini kaÃ§Ä±rmak (false negative) ile saÄŸlÄ±klÄ± birini yanlÄ±ÅŸ alarm (false positive) 
    vermek arasÄ±nda denge kurmasÄ± gerekiyordu.
    </div>
    """, unsafe_allow_html=True)
    
    # Interactive demo
    st.markdown("### ğŸ® Ä°nteraktif Demo")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**âš™ï¸ Senaryoyu Ayarla:**")
        class_0_size = st.slider("SÄ±nÄ±f 0 Ã¶rneklerinin sayÄ±sÄ±", 10, 200, 150)
        class_1_size = st.slider("SÄ±nÄ±f 1 Ã¶rneklerinin sayÄ±sÄ±", 10, 200, 50)
        accuracy_class_0 = st.slider("SÄ±nÄ±f 0 doÄŸru tahmin oranÄ± (%)", 0, 100, 80) / 100
        accuracy_class_1 = st.slider("SÄ±nÄ±f 1 doÄŸru tahmin oranÄ± (%)", 0, 100, 70) / 100
    
    with col2:
        # Calculate metrics
        correct_0 = int(class_0_size * accuracy_class_0)
        correct_1 = int(class_1_size * accuracy_class_1)
        total_correct = correct_0 + correct_1
        total_samples = class_0_size + class_1_size
        
        normal_accuracy = total_correct / total_samples
        balanced_acc = (accuracy_class_0 + accuracy_class_1) / 2
        
        st.markdown("**ğŸ“Š SonuÃ§lar:**")
        st.metric("Normal Accuracy", f"{normal_accuracy:.2%}")
        st.metric("Balanced Accuracy", f"{balanced_acc:.2%}")
        
        # Visual comparison
        fig = go.Figure(data=[
            go.Bar(name='Normal Accuracy', x=['Metrik'], y=[normal_accuracy], marker_color='lightblue'),
            go.Bar(name='Balanced Accuracy', x=['Metrik'], y=[balanced_acc], marker_color='lightcoral')
        ])
        fig.update_layout(title='Accuracy KarÅŸÄ±laÅŸtÄ±rmasÄ±', yaxis_title='DeÄŸer')
        st.plotly_chart(fig, use_container_width=True)
    
    # Real example
    st.markdown("### ğŸ”¬ GerÃ§ek Veri Ã–rneÄŸi")
    y_true, y_pred, _ = create_sample_data()
    
    normal_acc = np.mean(y_true == y_pred)
    balanced_acc_real = balanced_accuracy_score(y_true, y_pred)
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Normal Accuracy", f"{normal_acc:.3f}")
    with col2:
        st.metric("Balanced Accuracy", f"{balanced_acc_real:.3f}")
    
    # Confusion matrix
    fig = plot_confusion_matrix(y_true, y_pred, "Ã–rnek Veri Confusion Matrix")
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("""
    <div class="fun-fact">
    <h3>ğŸ’¡ Ne Zaman KullanmalÄ±?</h3>
    <p>â€¢ Veri setinde sÄ±nÄ±flar eÅŸit daÄŸÄ±lmadÄ±ÄŸÄ±nda<br>
    â€¢ Her sÄ±nÄ±fÄ±n eÅŸit Ã¶nemde olduÄŸu durumlarda<br>
    â€¢ Medical diagnosis gibi kritik uygulamalarda</p>
    </div>
    """, unsafe_allow_html=True)

def matthews_correlation_page():
    """Matthews Correlation Coefficient explanation page"""
    st.markdown("# ğŸ”— Matthews Correlation Coefficient (MCC)")
    
    st.markdown("""
    <div class="explanation-box">
    <h2>ğŸ¤” MCC Nedir?</h2>
    <p><strong>Basit aÃ§Ä±klama:</strong> Machine learning dÃ¼nyasÄ±nÄ±n korelasyon katsayÄ±sÄ±! 
    -1 ile +1 arasÄ±nda deÄŸer alÄ±r ve modelin ne kadar gÃ¼venilir olduÄŸunu sÃ¶yler.</p>
    
    <p><strong>GerÃ§ek hayat analojisi:</strong> Hava durumu tahmininde:<br>
    â€¢ +1: MÃ¼kemmel tahmin (her zaman doÄŸru)<br>
    â€¢ 0: Rastgele tahmin kadar iyi<br>
    â€¢ -1: Her zaman yanlÄ±ÅŸ (bu da aslÄ±nda bir bilgi!)</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Formula explanation
    st.markdown("### ğŸ“ FormÃ¼l")
    
    st.latex(r'''
    MCC = \frac{TP \times TN - FP \times FN}{\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}
    ''')
    
    st.markdown("""
    **ğŸ§  FormÃ¼lÃ¼n MantÄ±ÄŸÄ±:**
    
    Bu formÃ¼l **Pearson korelasyon katsayÄ±sÄ±nÄ±n** binary classification'a uyarlanmÄ±ÅŸ hali:
    
    - **Pay (Numerator)**: "Ä°yi tahminler" - "KÃ¶tÃ¼ tahminler"
    - **Payda (Denominator)**: Normalizasyon faktÃ¶rÃ¼ â†’ Sonucun -1 ile +1 arasÄ±nda olmasÄ±nÄ± saÄŸlar
    """)
    
    st.latex(r'''
    \text{Pay} = TP \times TN - FP \times FN
    ''')
    
    st.latex(r'''
    \text{Payda} = \sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}
    ''')
    
    st.markdown("""
    
    **ğŸ’¡ Neden Bu FormÃ¼l?**
    """)
    
    st.latex(r'''
    TP \times TN: \text{Hem pozitif hem negatif sÄ±nÄ±fÄ± doÄŸru tahmin (iyi!)}
    ''')
    
    st.latex(r'''
    FP \times FN: \text{Pozitifi negatif, negatifi pozitif tahmin (kÃ¶tÃ¼!)}
    ''')
    
    st.latex(r'''
    \text{Fark} = (TP \times TN) - (FP \times FN): \text{Net baÅŸarÄ±mÄ±z}
    ''')
    
    st.markdown("""
    - **KarekÃ¶k**: TÃ¼m confusion matrix deÄŸerlerinin etkisini dengeler
    """)
    
    st.markdown("""
    <div style="background: #f0f8ff; padding: 1rem; border-radius: 8px; border-left: 4px solid #4169E1;">
    <strong>ğŸ“š TarihÃ§e:</strong> Brian W. Matthews tarafÄ±ndan 1975'te protein structure prediction iÃ§in geliÅŸtirildi. 
    O zamanlar da imbalanced biological data'yla uÄŸraÅŸÄ±yorlardÄ±! FormÃ¼l, matematiksel olarak 
    Phi coefficient (Ï†) ile aynÄ±dÄ±r - bu da 2x2 tablo iÃ§in chi-square testinin Ã¶zel halidir.
    </div>
    """, unsafe_allow_html=True)
    
    # Visual explanation
    st.markdown("### ğŸ“Š MCC DeÄŸerlerinin AnlamÄ±")
    
    mcc_values = [-1, -0.5, 0, 0.5, 1]
    mcc_meanings = [
        "Tamamen YanlÄ±ÅŸ ğŸ˜±",
        "KÃ¶tÃ¼ Model ğŸ˜", 
        "Rastgele Tahmin ğŸ²",
        "Ä°yi Model ğŸ˜Š",
        "MÃ¼kemmel Model ğŸ¯"
    ]
    
    fig = go.Figure()
    colors = ['red', 'orange', 'yellow', 'lightgreen', 'green']
    
    for i, (val, meaning, color) in enumerate(zip(mcc_values, mcc_meanings, colors)):
        fig.add_trace(go.Scatter(
            x=[val], y=[i], 
            mode='markers+text',
            marker=dict(size=20, color=color),
            text=f"{val}<br>{meaning}",
            textposition="middle right",
            name=meaning
        ))
    
    fig.update_layout(
        title="MCC DeÄŸer SkalasÄ±",
        xaxis_title="MCC DeÄŸeri",
        yaxis=dict(showticklabels=False),
        height=400
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Interactive calculator
    st.markdown("### ğŸ§® MCC HesaplayÄ±cÄ±")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Confusion Matrix DeÄŸerlerini Girin:**")
        tp = st.number_input("True Positive (TP)", min_value=0, value=85)
        tn = st.number_input("True Negative (TN)", min_value=0, value=90)
        fp = st.number_input("False Positive (FP)", min_value=0, value=10)
        fn = st.number_input("False Negative (FN)", min_value=0, value=15)
    
    with col2:
        # Calculate MCC
        numerator = (tp * tn) - (fp * fn)
        denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
        
        if denominator == 0:
            mcc = 0
        else:
            mcc = numerator / denominator
        
        st.markdown("**ğŸ“Š SonuÃ§:**")
        st.metric("MCC DeÄŸeri", f"{mcc:.3f}")
        
        # Interpretation
        if mcc > 0.8:
            interpretation = "ğŸ¯ MÃ¼kemmel!"
        elif mcc > 0.6:
            interpretation = "ğŸ˜Š Ã‡ok Ä°yi!"
        elif mcc > 0.4:
            interpretation = "ğŸ‘ Ä°yi"
        elif mcc > 0.2:
            interpretation = "ğŸ˜ Orta"
        elif mcc > 0:
            interpretation = "ğŸ‘ ZayÄ±f"
        else:
            interpretation = "ğŸ˜± KÃ¶tÃ¼"
        
        st.markdown(f"**DeÄŸerlendirme:** {interpretation}")
        
        # Visual confusion matrix
        cm_data = [[tp, fp], [fn, tn]]
        fig = px.imshow(cm_data, 
                       labels=dict(x="Tahmin", y="GerÃ§ek"),
                       x=['Positive', 'Negative'],
                       y=['Positive', 'Negative'],
                       title="Confusion Matrix GÃ¶rselleÅŸtirme")
        
        for i in range(2):
            for j in range(2):
                fig.add_annotation(x=j, y=i, text=str(cm_data[i][j]),
                                 showarrow=False, font_color="white")
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Real example
    st.markdown("### ğŸ”¬ GerÃ§ek Veri Ã–rneÄŸi")
    y_true, y_pred, _ = create_sample_data()
    
    # For binary classification, we'll use first two classes
    binary_mask = (y_true <= 1) & (y_pred <= 1)
    y_true_binary = y_true[binary_mask]
    y_pred_binary = y_pred[binary_mask]
    
    if len(y_true_binary) > 0:
        mcc_real = matthews_corrcoef(y_true_binary, y_pred_binary)
        st.metric("Ã–rnek Veri MCC", f"{mcc_real:.3f}")
    
    st.markdown("""
    <div class="fun-fact">
    <h3>ğŸŒŸ MCC'nin SÃ¼per GÃ¼Ã§leri</h3>
    <p>â€¢ Ä°mbalanced data'da bile gÃ¼venilir<br>
    â€¢ TÃ¼m confusion matrix deÄŸerlerini dikkate alÄ±r<br>
    â€¢ KarÅŸÄ±laÅŸtÄ±rma yapmak iÃ§in mÃ¼kemmel (-1 to +1 range)<br>
    â€¢ Medical diagnosis iÃ§in altÄ±n standart</p>
    </div>
    """, unsafe_allow_html=True)

def cohens_kappa_page():
    """Cohen's Kappa explanation page"""
    st.markdown("# ğŸ¤ Cohen's Kappa")
    
    st.markdown("""
    <div class="explanation-box">
    <h2>ğŸ¤” Cohen's Kappa Nedir?</h2>
    <p><strong>Basit aÃ§Ä±klama:</strong> Ä°ki deÄŸerlendirmeci arasÄ±ndaki uyuÅŸma seviyesini Ã¶lÃ§er! 
    Sadece "ÅŸans eseri uyuÅŸma"yÄ± Ã§Ä±karÄ±p gerÃ§ek uyuÅŸmayÄ± bulur.</p>
    
    <p><strong>Medical Ã¶rnek:</strong> Depresyon teÅŸhisi iÃ§in yeni bir araÃ§ geliÅŸtirdiniz. 
    Ä°ki doktor bu aracÄ± kullanarak 50 hastayÄ± deÄŸerlendiriyor. 
    Ä°kisi de aynÄ± sonuca varÄ±yor mu, yoksa ÅŸans eseri mi uyuÅŸuyorlar? 
    Cohen's Kappa tam da bunu Ã¶lÃ§er!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Formula explanation
    st.markdown("### ğŸ“ FormÃ¼l")
    
    st.latex(r'''
    \kappa = \frac{P_o - P_e}{1 - P_e}
    ''')
    
    st.markdown("**AÃ§Ä±lÄ±mÄ±:**")
    
    st.latex(r'''
    P_o = \frac{\text{GÃ¶zlenen UyuÅŸma}}{\text{Toplam}} \quad P_e = \sum_{i} \frac{n_{i+} \times n_{+i}}{N^2}
    ''')
    
    # Add Cohen.png image
    st.image("Cohen.png", caption="Cohen's Kappa Hesaplama Ã–rneÄŸi", use_container_width=True)
    
    st.markdown("""
    **ğŸ§  AdÄ±m AdÄ±m Hesaplama Ã–rneÄŸi:**
    
    **ğŸ¥ Senaryo:** Ä°ki doktor (Rater 1 ve Rater 2) 50 hastayÄ± "Depresif" veya "Depresif DeÄŸil" olarak deÄŸerlendiriyor.
    
    **ğŸ“Š SonuÃ§lar:**
    - Her ikisi de "Depresif DeÄŸil" dedi: 17 hasta
    - Her ikisi de "Depresif" dedi: 19 hasta  
    - Rater 1 "Depresif DeÄŸil", Rater 2 "Depresif": 8 hasta
    - Rater 1 "Depresif", Rater 2 "Depresif DeÄŸil": 6 hasta
    
    **ğŸ“ Hesaplama:**
    
    **1. AdÄ±m - GÃ¶zlenen UyuÅŸma (Po):**
    """)
    
    st.latex(r'''
    P_o = \frac{17 + 19}{50} = \frac{36}{50} = 0.72 = 72\%
    ''')
    
    st.markdown("""
    **2. AdÄ±m - Beklenen UyuÅŸma (Pe):**
    """)
    
    st.latex(r'''
    \text{Rater 1: } \frac{25}{50} = 50\% \text{ "Depresif DeÄŸil", } \frac{25}{50} = 50\% \text{ "Depresif"}
    ''')
    
    st.latex(r'''
    \text{Rater 2: } \frac{23}{50} = 46\% \text{ "Depresif DeÄŸil", } \frac{27}{50} = 54\% \text{ "Depresif"}
    ''')
    
    st.latex(r'''
    P_e = (0.50 \times 0.46) + (0.50 \times 0.54) = 0.23 + 0.27 = 0.50
    ''')
    
    st.markdown("""
    **3. AdÄ±m - Cohen's Kappa:**
    """)
    
    st.latex(r'''
    \kappa = \frac{P_o - P_e}{1 - P_e} = \frac{0.72 - 0.50}{1 - 0.50} = \frac{0.22}{0.50} = \mathbf{0.44}
    ''')
    
    st.markdown("""
    """)
    
    st.markdown("""
    <div style="background: #f9f7ff; padding: 1rem; border-radius: 8px; border-left: 4px solid #9C27B0;">
    <strong>ğŸ“š TarihÃ§e:</strong> Jacob Cohen tarafÄ±ndan 1960'da psikoloji araÅŸtÄ±rmalarÄ± iÃ§in geliÅŸtirildi. 
    O dÃ¶nem iki psikolog aynÄ± hastayÄ± deÄŸerlendirdiÄŸinde ne kadar uyuÅŸtuklarÄ± merak ediliyordu. 
    Cohen, sadece "kaÃ§ tanede uyuÅŸtular" deÄŸil, "bu uyuÅŸma ne kadar anlamlÄ±" sorusunu sordu.
    </div>
    """, unsafe_allow_html=True)
    
    # Kappa interpretation scale
    st.markdown("### ğŸ“Š Kappa DeÄŸer SkalasÄ±")
    
    kappa_ranges = [
        (-1.0, 0.0, "KÃ¶tÃ¼den KÃ¶tÃ¼ ğŸ˜±", "#8B0000", "white"),  # Dark red with white text
        (0.0, 0.20, "ZayÄ±f UyuÅŸma ğŸ˜", "#DC143C", "white"),  # Crimson with white text
        (0.21, 0.40, "Adil UyuÅŸma ğŸ˜", "#FF8C00", "black"),  # Dark orange with black text
        (0.41, 0.60, "Orta UyuÅŸma ğŸ‘", "#FFD700", "black"),  # Gold with black text
        (0.61, 0.80, "Ä°yi UyuÅŸma ğŸ˜Š", "#32CD32", "black"),  # Lime green with black text
        (0.81, 1.00, "Ã‡ok Ä°yi UyuÅŸma ğŸ¯", "#228B22", "white")  # Forest green with white text
    ]
    
    fig = go.Figure()
    
    for i, (min_val, max_val, meaning, bg_color, text_color) in enumerate(kappa_ranges):
        # Add colored rectangle with border
        fig.add_shape(
            type="rect",
            x0=min_val, y0=i-0.35, x1=max_val, y1=i+0.35,
            fillcolor=bg_color, 
            opacity=0.9, 
            line=dict(color="black", width=2)
        )
        
        # Add text annotation with better contrast
        fig.add_annotation(
            x=(min_val + max_val)/2, y=i,
            text=f"<b>{min_val:.2f} - {max_val:.2f}</b><br><b>{meaning}</b>",
            showarrow=False, 
            font=dict(size=16, color=text_color, family="Arial Black"),
            bgcolor="rgba(255,255,255,0.8)" if text_color == "black" else "rgba(0,0,0,0.3)",
            bordercolor="black",
            borderwidth=1
        )
    
    fig.update_layout(
        title=dict(
            text="<b>Cohen's Kappa DeÄŸerlendirme SkalasÄ± (Landis & Koch)</b>",
            font=dict(size=18, color="darkblue"),
            x=0.5
        ),
        xaxis=dict(
            title=dict(
                text="<b>Kappa DeÄŸeri</b>",
                font=dict(size=14, color="darkblue")
            ),
            tickfont=dict(size=12),
            gridcolor="lightgray",
            gridwidth=1
        ),
        yaxis=dict(
            showticklabels=False, 
            range=[-0.6, 5.6],
            showgrid=False
        ),
        height=480,
        plot_bgcolor="white",
        paper_bgcolor="white",
        margin=dict(l=20, r=20, t=60, b=40)
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Interactive example
    st.markdown("### ğŸ® Ä°nteraktif Kappa HesaplayÄ±cÄ±")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Senaryo: Medical DeÄŸerlendirme**")
        st.markdown("Ä°ki doktor hastalarÄ± 'Depresif' veya 'Depresif DeÄŸil' olarak deÄŸerlendiriyor:")
        
        both_not_depressed = st.slider("Ä°kisi de 'Depresif DeÄŸil' dediÄŸi hastalar", 0, 100, 17)
        both_depressed = st.slider("Ä°kisi de 'Depresif' dediÄŸi hastalar", 0, 100, 19)
        doctor1_not_doctor2_depressed = st.slider("1. Depresif DeÄŸil, 2. Depresif dediÄŸi hastalar", 0, 50, 8)
        doctor1_depressed_doctor2_not = st.slider("1. Depresif, 2. Depresif DeÄŸil dediÄŸi hastalar", 0, 50, 6)
    
    with col2:
        # Calculate observed and expected agreement
        total = both_not_depressed + both_depressed + doctor1_not_doctor2_depressed + doctor1_depressed_doctor2_not
        
        if total > 0:
            observed_agreement = (both_not_depressed + both_depressed) / total
            
            # Expected agreement by chance
            doctor1_not_total = both_not_depressed + doctor1_not_doctor2_depressed
            doctor1_depressed_total = both_depressed + doctor1_depressed_doctor2_not
            doctor2_not_total = both_not_depressed + doctor1_depressed_doctor2_not
            doctor2_depressed_total = both_depressed + doctor1_not_doctor2_depressed
            
            expected_not_depressed = (doctor1_not_total / total) * (doctor2_not_total / total)
            expected_depressed = (doctor1_depressed_total / total) * (doctor2_depressed_total / total)
            expected_agreement = expected_not_depressed + expected_depressed
            
            if expected_agreement < 1.0:
                kappa = (observed_agreement - expected_agreement) / (1 - expected_agreement)
            else:
                kappa = 1.0
            
            st.markdown("**ğŸ“Š SonuÃ§lar:**")
            st.metric("GÃ¶zlenen UyuÅŸma (Po)", f"{observed_agreement:.3f} ({observed_agreement:.1%})")
            st.metric("Beklenen UyuÅŸma (Pe)", f"{expected_agreement:.3f} ({expected_agreement:.1%})")
            st.metric("Cohen's Kappa", f"{kappa:.3f}")
            
            # Interpretation
            for min_val, max_val, meaning, bg_color, text_color in kappa_ranges:
                if min_val <= kappa <= max_val:
                    st.markdown(f"**DeÄŸerlendirme:** {meaning}")
                    break
        else:
            st.warning("Toplam hasta sayÄ±sÄ± 0 olamaz!")
    
    # Confusion matrix visualization
    if total > 0:
        st.markdown("### ğŸ“Š UyuÅŸma Matrisi")
        confusion_data = [[both_not_depressed, doctor1_not_doctor2_depressed], 
                         [doctor1_depressed_doctor2_not, both_depressed]]
        
        fig = px.imshow(confusion_data,
                       labels=dict(x="Doktor 2", y="Doktor 1"),
                       x=['Depresif DeÄŸil', 'Depresif'], y=['Depresif DeÄŸil', 'Depresif'],
                       title="DoktorlarÄ±n UyuÅŸma Matrisi")
        
        for i in range(2):
            for j in range(2):
                fig.add_annotation(x=j, y=i, text=str(confusion_data[i][j]),
                                 showarrow=False, font_color="white")
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Real example
    st.markdown("### ğŸ”¬ GerÃ§ek Veri Ã–rneÄŸi")
    y_true, y_pred, _ = create_sample_data()
    kappa_real = cohen_kappa_score(y_true, y_pred)
    
    st.metric("Ã–rnek Veri Kappa", f"{kappa_real:.3f}")
    
    st.markdown("""
    <div class="fun-fact">
    <h3>ğŸ¯ Kappa'nÄ±n KullanÄ±m AlanlarÄ±</h3>
    <p>â€¢ Medical diagnosis doÄŸruluÄŸu<br>
    â€¢ Makine Ã§evirisi kalitesi<br>
    â€¢ Annotation quality control<br>
    â€¢ Multi-rater studies</p>
    </div>
    """, unsafe_allow_html=True)

def quadratic_weighted_kappa_page():
    """Quadratic Weighted Kappa explanation page"""
    st.markdown("# âš–ï¸ Quadratic Weighted Kappa")
    
    st.markdown("""
    <div class="explanation-box">
    <h2>ğŸ¤” Quadratic Weighted Kappa Nedir?</h2>
    <p><strong>Basit aÃ§Ä±klama:</strong> Normal Kappa'nÄ±n geliÅŸmiÅŸ versiyonu! 
    <strong>Ordinal (sÄ±ralÄ±) deÄŸiÅŸkenler</strong>  iÃ§in kullanÄ±lÄ±r. HatalarÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ de dikkate alÄ±r.</p>
    
    <p><strong>Medical Ã¶rnek:</strong> Ä°ki doktor hasta memnuniyetini deÄŸerlendiriyor:<br>
    â€¢ <strong>Memnun DeÄŸil</strong> â†’ <strong>NÃ¶tr</strong> â†’ <strong>Memnun</strong> (sÄ±ralÄ± kategoriler)<br>
    â€¢ "Memnun DeÄŸil" yerine "NÃ¶tr" demek â†’ KÃ¼Ã§Ã¼k hata<br>
    â€¢ "Memnun DeÄŸil" yerine "Memnun" demek â†’ BÃ¼yÃ¼k hata<br>
    Quadratic Kappa bÃ¼yÃ¼k hatalarÄ± Ã§ok daha aÄŸÄ±r cezalandÄ±rÄ±r!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Add visual explanation of nominal vs ordinal
    st.markdown("### ğŸ“Š Nominal vs Ordinal FarkÄ±")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <strong>ğŸ”¤ Nominal (Normal Kappa):</strong><br>
        - SÄ±ra YOK<br>
        - Kategoriler: Kedi, KÃ¶pek, KuÅŸ<br>
        - TÃ¼m hatalar eÅŸit
        """, unsafe_allow_html=True)
        
    with col2:
        st.markdown("""
        <strong>ğŸ“ Ordinal (Weighted Kappa):</strong><br>
        - SÄ±ra VAR<br>
        - Kategoriler: Memnun DeÄŸil < NÃ¶tr < Memnun<br>
        - Hata bÃ¼yÃ¼klÃ¼ÄŸÃ¼ Ã¶nemli
        """, unsafe_allow_html=True)
    
    # Reference to DATAtab
    st.markdown("""
    <div style="background: #e8f5e8; padding: 1rem; border-radius: 8px; border-left: 4px solid #4CAF50;">
    <strong>ğŸ“š Kaynak:</strong> Bu anlatÄ±m <a href="https://datatab.net/tutorial/weighted-cohens-kappa" target="_blank">DATAtab Weighted Cohen's Kappa</a> 
    tutorialÄ±ndan adapte edilmiÅŸtir. Ordinal data iÃ§in weighted kappa kullanÄ±mÄ± detaylÄ± ÅŸekilde aÃ§Ä±klanmÄ±ÅŸtÄ±r.
    </div>
    """, unsafe_allow_html=True)
    
    # Formula explanation
    st.markdown("### ğŸ“ FormÃ¼l")
    
    st.latex(r'''
    \kappa_w = 1 - \frac{\sum_{i,j} w_{ij} O_{ij}}{\sum_{i,j} w_{ij} E_{ij}}
    ''')
    
    st.markdown("**AÄŸÄ±rlÄ±k matrisi (Quadratic):**")
    
    st.latex(r'''
    w_{ij} = \frac{(i-j)^2}{(N-1)^2}
    ''')
    
    st.markdown("### ğŸ”„ Linear vs Quadratic Weighting")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("<strong>ğŸ“ Linear Weighting:</strong>", unsafe_allow_html=True)
        st.latex(r'''
        w_{ij} = \frac{|i-j|}{N-1}
        ''')
        st.markdown("Mesafeyle doÄŸru orantÄ±lÄ± ceza")
        
    with col2:
        st.markdown("<strong>ğŸ“ Quadratic Weighting:</strong>", unsafe_allow_html=True)
        st.latex(r'''
        w_{ij} = \frac{(i-j)^2}{(N-1)^2}
        ''')
        st.markdown("Mesafenin karesi kadar ceza!")
    
    st.markdown("""
    <strong>ğŸ§  3 Kategorili Ã–rnek (Memnun DeÄŸil=0, NÃ¶tr=1, Memnun=2):</strong>
    """, unsafe_allow_html=True)
    
    # Create comparison table for 3x3 case
    weighting_comparison = pd.DataFrame({
        'Hata': ['0â†’1', '0â†’2', '1â†’0', '1â†’2', '2â†’0', '2â†’1'],
        'Mesafe': [1, 2, 1, 1, 2, 1],
        'Linear Weight': [0.5, 1.0, 0.5, 0.5, 1.0, 0.5],
        'Quadratic Weight': [0.25, 1.0, 0.25, 0.25, 1.0, 0.25]
    })
    st.dataframe(weighting_comparison, use_container_width=True)
    
    st.markdown("""
    <strong>ğŸ’¡ Neden Quadratic Weight?</strong><br>
    Quadratic weighting bÃ¼yÃ¼k hatalarÄ± Ã§ok daha aÄŸÄ±r cezalandÄ±rÄ±r:
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div style="background: #fff3e0; padding: 1rem; border-radius: 8px; border-left: 4px solid #FF9800;">
    <strong>ğŸ“š TarihÃ§e:</strong> Bu metrik Ã¶zellikle <strong> ordinal (sÄ±ralÄ±) kategoriler</strong>  iÃ§in geliÅŸtirildi. 
    TÄ±pta hastalÄ±k severity (hafifâ†’ortaâ†’ÅŸiddetli), eÄŸitimde notlar (Aâ†’Bâ†’Câ†’Dâ†’F), 
    psikolojide likert scales gibi durumlarda kullanÄ±lÄ±r. "5 yerine 4 demek, 5 yerine 1 demekten Ã§ok daha az kÃ¶tÃ¼!"
    </div>
    """, unsafe_allow_html=True)
    
    # Weight matrix visualization
    st.markdown("### âš–ï¸ AÄŸÄ±rlÄ±k Matrisi NasÄ±l Ã‡alÄ±ÅŸÄ±r?")
    
    # Create weight matrix example for 5 classes
    n_classes = 5
    weight_matrix = np.zeros((n_classes, n_classes))
    
    for i in range(n_classes):
        for j in range(n_classes):
            weight_matrix[i, j] = (i - j) ** 2 / (n_classes - 1) ** 2
    
    fig = px.imshow(weight_matrix,
                   labels=dict(x="Tahmin Edilen SÄ±nÄ±f", y="GerÃ§ek SÄ±nÄ±f", color="Ceza AÄŸÄ±rlÄ±ÄŸÄ±"),
                   title="Quadratic Weight Matrix (5 SÄ±nÄ±f Ä°Ã§in)",
                   color_continuous_scale='Reds')
    
    for i in range(n_classes):
        for j in range(n_classes):
            fig.add_annotation(x=j, y=i, text=f"{weight_matrix[i, j]:.2f}",
                             showarrow=False, 
                             font_color="white" if weight_matrix[i, j] > 0.5 else "black")
    
    st.plotly_chart(fig, use_container_width=True)
    
    st.latex(r'''
    \text{BÃ¼yÃ¼k hata (0â†’2): } 1.0 \text{ vs KÃ¼Ã§Ã¼k hata (0â†’1): } 0.25 \text{ â†’ 4 kat fark!}
    ''')
    
    # Interactive example based on DATAtab
    st.markdown("### ğŸ® Hasta Memnuniyeti Ã–rneÄŸi (DATAtab)")
    st.markdown("<strong>Ä°ki doktor 75 hastanÄ±n tedavi memnuniyetini deÄŸerlendiriyor:</strong>", unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("<strong>Confusion Matrix (3x3):</strong>", unsafe_allow_html=True)
        
        # Create 3x3 confusion matrix based on DATAtab example
        confusion_input = np.zeros((3, 3))
        
        categories = ["Memnun DeÄŸil", "NÃ¶tr", "Memnun"]
        
        for i in range(3):
            st.markdown(f"<strong>Doktor 1: {categories[i]}</strong>", unsafe_allow_html=True)
            cols = st.columns(3)
            for j in range(3):
                with cols[j]:
                    # Default values from DATAtab example
                    default_values = [
                        [15, 3, 0],   # Memnun DeÄŸil
                        [5, 20, 2],   # NÃ¶tr  
                        [2, 8, 20]    # Memnun
                    ]
                    confusion_input[i, j] = st.number_input(
                        f"â†’ {categories[j][:4]}", 
                        min_value=0, 
                        value=default_values[i][j],
                        key=f"conf_3x3_{i}_{j}"
                    )
    
    with col2:
        # Calculate both linear and quadratic weighted kappa for 3x3
        def calculate_weighted_kappa(confusion_matrix, weight_type="quadratic"):
            n_classes = confusion_matrix.shape[0]
            
            # Weight matrix
            weight_matrix = np.zeros((n_classes, n_classes))
            for i in range(n_classes):
                for j in range(n_classes):
                    if weight_type == "linear":
                        weight_matrix[i, j] = abs(i - j) / (n_classes - 1)
                    else:  # quadratic
                        weight_matrix[i, j] = (i - j) ** 2 / (n_classes - 1) ** 2
            
            # Observed weighted agreement
            total = np.sum(confusion_matrix)
            observed = 1 - np.sum(weight_matrix * confusion_matrix) / total
            
            # Expected weighted agreement
            row_totals = np.sum(confusion_matrix, axis=1)
            col_totals = np.sum(confusion_matrix, axis=0)
            expected_matrix = np.outer(row_totals, col_totals) / total
            expected = 1 - np.sum(weight_matrix * expected_matrix) / total
            
            if expected == 1.0:
                return 1.0
            else:
                return (observed - expected) / (1 - expected)
        
        total_patients = np.sum(confusion_input)
        
        if total_patients > 0:
            linear_kappa = calculate_weighted_kappa(confusion_input, "linear")
            quadratic_kappa = calculate_weighted_kappa(confusion_input, "quadratic")
            
            st.markdown("<strong>ğŸ“Š SonuÃ§lar:</strong>", unsafe_allow_html=True)
            st.metric("Toplam Hasta", f"{int(total_patients)}")
            st.metric("Linear Weighted Kappa", f"{linear_kappa:.3f}")
            st.metric("Quadratic Weighted Kappa", f"{quadratic_kappa:.3f}")
            
            # Show confusion matrix
            fig = px.imshow(confusion_input,
                           labels=dict(x="Doktor 2", y="Doktor 1"),
                           x=categories, y=categories,
                           title="Hasta Memnuniyeti Confusion Matrix")
            
            for i in range(3):
                for j in range(3):
                    fig.add_annotation(x=j, y=i, text=str(int(confusion_input[i, j])),
                                     showarrow=False, font_color="white")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Weight matrix visualization
            st.markdown("<strong>âš–ï¸ Quadratic Weight Matrix:</strong>", unsafe_allow_html=True)
            weight_matrix = np.zeros((3, 3))
            for i in range(3):
                for j in range(3):
                    weight_matrix[i, j] = (i - j) ** 2 / (3 - 1) ** 2
            
            weight_df = pd.DataFrame(weight_matrix)
            weight_df.index = categories
            weight_df.columns = categories
            st.dataframe(weight_df.round(3), use_container_width=True)
            
            # Detailed agreement analysis
            perfect_agreement = confusion_input[0,0] + confusion_input[1,1] + confusion_input[2,2]
            one_step_errors = confusion_input[0,1] + confusion_input[1,0] + confusion_input[1,2] + confusion_input[2,1]
            two_step_errors = confusion_input[0,2] + confusion_input[2,0]
            
            st.markdown("<strong>ğŸ” UyuÅŸma Analizi:</strong>", unsafe_allow_html=True)
            st.metric("Tam UyuÅŸma", f"{int(perfect_agreement)} hasta")
            st.metric("1 AdÄ±m Hata", f"{int(one_step_errors)} hasta")
            st.metric("2 AdÄ±m Hata", f"{int(two_step_errors)} hasta")
    
    st.markdown("""
    ### ğŸ“‹ AdÄ±m AdÄ±m Hesaplama Ã–rneÄŸi
    
    DATAtab Ã¶rneÄŸinden (75 hasta, 3 kategori):
    """)
    
    st.latex(r'''
    \text{1. Weight Matrix oluÅŸtur: } w_{ij} = \frac{(i-j)^2}{(N-1)^2}
    ''')
    
    st.latex(r'''
    \text{2. Observed Agreement: } P_o^w = 1 - \frac{\sum w_{ij} \cdot O_{ij}}{n}
    ''')
    
    st.latex(r'''
    \text{3. Expected Agreement: } P_e^w = 1 - \frac{\sum w_{ij} \cdot E_{ij}}{n}
    ''')
    
    st.latex(r'''
    \text{4. Weighted Kappa: } \kappa_w = \frac{P_o^w - P_e^w}{1 - P_e^w}
    ''')
    
    st.markdown("""
    <div class="fun-fact">
    <h3>ğŸŒŸ Weighted Kappa'nÄ±n KullanÄ±m AlanlarÄ±</h3>
    <p>â€¢ <strong>Medical Assessment</strong>: HastalÄ±k severity, tedavi response<br>
    â€¢ <strong>Education</strong>: Ã–ÄŸrenci performans deÄŸerlendirmesi<br>
    â€¢ <strong>Psychology</strong>: Likert scale anketler<br>
    â€¢ <strong>Quality Control</strong>: ÃœrÃ¼n kalite sÄ±nÄ±flandÄ±rmasÄ±<br>
    â€¢ <strong>Kaggle</strong>: Ordinal prediction competitions</p>
    </div>
    """, unsafe_allow_html=True)

def log_loss_page():
    """Log Loss explanation page"""
    st.markdown("# ğŸ“‰ Log Loss")
    
    st.markdown("""
    <div class="explanation-box">
    <h2>ğŸ¤” Log Loss Nedir?</h2>
    <p><strong>Basit aÃ§Ä±klama:</strong> Modelin ne kadar "emin" olduÄŸunu Ã¶lÃ§er! 
    YanlÄ±ÅŸ tahminlerde Ã§ok emin olmayÄ± aÄŸÄ±r cezalandÄ±rÄ±r.</p>
    
    <p><strong>GerÃ§ek hayat analojisi:</strong> Hava durumu tahmini:<br>
    â€¢ "YaÄŸmur %90 ihtimal" deyip gÃ¼neÅŸli Ã§Ä±karsa â†’ BÃ¼yÃ¼k ceza<br>
    â€¢ "YaÄŸmur %55 ihtimal" deyip gÃ¼neÅŸli Ã§Ä±karsa â†’ KÃ¼Ã§Ã¼k ceza<br>
    AÅŸÄ±rÄ± gÃ¼ven kÃ¶tÃ¼, makul ÅŸÃ¼phe iyi!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Formula explanation
    st.markdown("### ğŸ“ FormÃ¼l")
    
    st.markdown("**Binary Classification:**")
    st.latex(r'''
    \text{Log Loss} = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1-y_i) \log(1-p_i)]
    ''')
    
    st.markdown("**Multi-class Classification:**")
    st.latex(r'''
    \text{Log Loss} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{M} y_{ij} \log(p_{ij})
    ''')
    
    st.markdown("""
    **ğŸ§  FormÃ¼lÃ¼n MantÄ±ÄŸÄ±:**
    
    Bu formÃ¼l **modelin gÃ¼ven seviyesini** cezalandÄ±rmak iÃ§in tasarlandÄ±:
    
    - **yi**: GerÃ§ek label (0 veya 1 binary'de)
    - **pi**: Model'in tahmin ettiÄŸi probability
    - **log(pi)**: Logaritmik ceza â†’ DÃ¼ÅŸÃ¼k probability'lerde Ã§ok bÃ¼yÃ¼r!
    - **Negatif iÅŸaret**: Loss'u pozitif yapmak iÃ§in
    
    **ğŸ’¡ Neden Logaritma?**
    """)
    
    st.latex(r'''
    p = 0.9 \rightarrow \log(0.9) = -0.046 \rightarrow \text{KÃ¼Ã§Ã¼k ceza}
    ''')
    
    st.latex(r'''
    p = 0.1 \rightarrow \log(0.1) = -1.0 \rightarrow \text{BÃ¼yÃ¼k ceza}
    ''')
    
    st.latex(r'''
    p = 0.01 \rightarrow \log(0.01) = -2.0 \rightarrow \text{Ã‡ok bÃ¼yÃ¼k ceza!}
    ''')
    
    st.markdown("""
    
    **AÅŸÄ±rÄ± gÃ¼venli yanlÄ±ÅŸ tahminler Ã§ok aÄŸÄ±r cezalandÄ±rÄ±lÄ±r!**
    """)
    
    st.markdown("""
    <div style="background: #f3e5f5; padding: 1rem; border-radius: 8px; border-left: 4px solid #E91E63;">
    <strong>ğŸ“š TarihÃ§e:</strong> Log Loss aslÄ±nda **information theory**'den gelir. Claude Shannon'Ä±n 1948'deki 
    "bilgi entropisi" kavramÄ±na dayanÄ±r. Bir olayÄ±n gerÃ§ekleÅŸme probability'si dÃ¼ÅŸtÃ¼kÃ§e, 
    o olayÄ±n "information content" artar. Yani nadir olaylarÄ± yanlÄ±ÅŸ tahmin etmek daha fazla "bilgi kaybÄ±" demektir!
    Bu yÃ¼zden Neural Network'ler de Cross-Entropy Loss (aynÄ± ÅŸey) kullanÄ±r.
    </div>
    """, unsafe_allow_html=True)
    
    # Interactive probability demo
    st.markdown("### ğŸ¯ Probability Confidence Demo")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Senaryo Kurgusu:**")
        true_class = st.selectbox("GerÃ§ek sÄ±nÄ±f", [0, 1], index=1)
        predicted_prob = st.slider("Model'in sÄ±nÄ±f 1 iÃ§in tahmini (%)", 0.0, 100.0, 80.0) / 100
        
        # Calculate log loss for this single prediction
        epsilon = 1e-15  # To avoid log(0)
        if true_class == 1:
            single_log_loss = -np.log(max(predicted_prob, epsilon))
        else:
            single_log_loss = -np.log(max(1 - predicted_prob, epsilon))
        
        st.metric("Bu Tahmin Ä°Ã§in Log Loss", f"{single_log_loss:.3f}")
    
    with col2:
        # Visualization of how confidence affects loss
        prob_range = np.linspace(0.01, 0.99, 100)
        
        # Log loss for correct prediction (true class = 1)
        correct_loss = -np.log(prob_range)
        # Log loss for incorrect prediction (true class = 0)
        incorrect_loss = -np.log(1 - prob_range)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=prob_range, y=correct_loss, 
                               name='DoÄŸru Tahmin (True=1)', 
                               line=dict(color='green')))
        fig.add_trace(go.Scatter(x=prob_range, y=incorrect_loss, 
                               name='YanlÄ±ÅŸ Tahmin (True=0)', 
                               line=dict(color='red')))
        
        # Add current prediction point
        current_loss = single_log_loss
        fig.add_trace(go.Scatter(x=[predicted_prob], y=[current_loss],
                               mode='markers', marker=dict(size=15, color='blue'),
                               name='Sizin Tahmininiz'))
        
        fig.update_layout(
            title="Confidence vs Log Loss",
            xaxis_title="Predicted Probability",
            yaxis_title="Log Loss",
            yaxis=dict(range=[0, 5])
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Multi-class demo
    st.markdown("### ğŸ® Multi-Class Log Loss Calculator")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**3 SÄ±nÄ±flÄ± Bir Problem:**")
        st.markdown("Animal Classification: Kedi, KÃ¶pek, KuÅŸ")
        
        true_animal = st.selectbox("GerÃ§ek hayvan", ["Kedi (0)", "KÃ¶pek (1)", "KuÅŸ (2)"])
        true_class_idx = int(true_animal.split("(")[1].split(")")[0])
        
        st.markdown("**Model'in tahmin olasÄ±lÄ±klarÄ±:**")
        prob_cat = st.slider("Kedi olasÄ±lÄ±ÄŸÄ± (%)", 0.0, 100.0, 33.3) / 100
        prob_dog = st.slider("KÃ¶pek olasÄ±lÄ±ÄŸÄ± (%)", 0.0, 100.0, 33.3) / 100
        prob_bird = st.slider("KuÅŸ olasÄ±lÄ±ÄŸÄ± (%)", 0.0, 100.0, 33.4) / 100
        
        # Normalize probabilities
        total_prob = prob_cat + prob_dog + prob_bird
        if total_prob > 0:
            prob_cat /= total_prob
            prob_dog /= total_prob
            prob_bird /= total_prob
        
        probs = [prob_cat, prob_dog, prob_bird]
        
    with col2:
        # Calculate log loss
        epsilon = 1e-15
        true_prob = max(probs[true_class_idx], epsilon)
        log_loss_value = -np.log(true_prob)
        
        st.markdown("**ğŸ“Š SonuÃ§lar:**")
        st.metric("Normalize EdilmiÅŸ OlasÄ±lÄ±klar", 
                 f"Kedi: {prob_cat:.2f}, KÃ¶pek: {prob_dog:.2f}, KuÅŸ: {prob_bird:.2f}")
        st.metric("Log Loss", f"{log_loss_value:.3f}")
        
        # Interpretation
        if log_loss_value < 0.5:
            interpretation = "ğŸ¯ Ã‡ok GÃ¼venli Tahmin!"
        elif log_loss_value < 1.0:
            interpretation = "ğŸ˜Š Ä°yi Tahmin"
        elif log_loss_value < 2.0:
            interpretation = "ğŸ˜ Orta Tahmin"
        else:
            interpretation = "ğŸ˜± KÃ¶tÃ¼ Tahmin"
        
        st.markdown(f"**DeÄŸerlendirme:** {interpretation}")
        
        # Probability bar chart
        fig = go.Figure(data=[
            go.Bar(x=['Kedi', 'KÃ¶pek', 'KuÅŸ'], 
                  y=[prob_cat, prob_dog, prob_bird],
                  marker_color=['lightcoral' if i == true_class_idx else 'lightblue' 
                               for i in range(3)])
        ])
        fig.update_layout(title="Model Tahmin OlasÄ±lÄ±klarÄ±", 
                         yaxis_title="OlasÄ±lÄ±k")
        st.plotly_chart(fig, use_container_width=True)
    
    # Real data example
    st.markdown("### ğŸ”¬ GerÃ§ek Veri Ã–rneÄŸi")
    y_true, y_pred, y_pred_proba = create_sample_data()
    
    # Calculate log loss
    real_log_loss = log_loss(y_true, y_pred_proba)
    st.metric("Ã–rnek Veri Log Loss", f"{real_log_loss:.3f}")
    
    # Show some predictions
    sample_indices = np.random.choice(len(y_true), 5, replace=False)
    sample_df = pd.DataFrame({
        'GerÃ§ek SÄ±nÄ±f': y_true[sample_indices],
        'Tahmin SÄ±nÄ±f': y_pred[sample_indices],
        'SÄ±nÄ±f 0 Prob': y_pred_proba[sample_indices, 0],
        'SÄ±nÄ±f 1 Prob': y_pred_proba[sample_indices, 1],
        'SÄ±nÄ±f 2 Prob': y_pred_proba[sample_indices, 2]
    })
    
    st.markdown("<strong>Ã–rnek Tahminler:</strong>", unsafe_allow_html=True)
    st.dataframe(sample_df, use_container_width=True)
    
    st.markdown("""
    <div class="fun-fact">
    <h3>ğŸ¯ Log Loss'un Ã–zellikleri</h3>
    <p>â€¢ Sadece doÄŸru/yanlÄ±ÅŸ deÄŸil, gÃ¼ven seviyesini de Ã¶lÃ§er<br>
    â€¢ AÅŸÄ±rÄ± gÃ¼venli yanlÄ±ÅŸ tahminleri aÄŸÄ±r cezalandÄ±rÄ±r<br>
    â€¢ Probability calibration iÃ§in mÃ¼kemmel<br>
    â€¢ Neural network training'de cross-entropy olarak kullanÄ±lÄ±r</p>
    </div>
    """, unsafe_allow_html=True)

def focal_loss_page():
    """Focal Loss explanation page"""
    st.markdown("# ğŸ” Focal Loss")
    
    st.markdown("""
    <div class="explanation-box">
    <h2>ğŸ¤” Focal Loss Nedir?</h2>
    <p><strong>Basit aÃ§Ä±klama:</strong> Log Loss'un akÄ±llÄ± versiyonu! 
    Kolay Ã¶rnekleri ihmal edip zor Ã¶rneklere odaklanÄ±r. Ã–zellikle imbalanced data'da Ã§ok iÅŸe yarar.</p>
    
    <p><strong>GerÃ§ek hayat analojisi:</strong> SÄ±nÄ±fta ders anlatan Ã¶ÄŸretmen:<br>
    â€¢ Anlayan Ã¶ÄŸrencilerle az zaman geÃ§irir<br>
    â€¢ Anlamayan Ã¶ÄŸrencilere daha Ã§ok zaman ayÄ±rÄ±r<br>
    Focal Loss da bÃ¶yle Ã§alÄ±ÅŸÄ±r - zor Ã¶rneklere daha Ã§ok odaklanÄ±r!</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Formula explanation
    st.markdown("### ğŸ“ FormÃ¼l")
    
    st.latex(r'''
    \text{Focal Loss} = -\alpha (1-p_t)^\gamma \log(p_t)
    ''')
    
    st.markdown("**Binary classification iÃ§in aÃ§Ä±lÄ±m:**")
    st.latex(r'''
    FL(p_t) = \begin{cases}
    -\alpha (1-p)^\gamma \log(p) & \text{if } y = 1 \\
    -(1-\alpha) p^\gamma \log(1-p) & \text{if } y = 0
    \end{cases}
    ''')
    
    st.markdown("""
    **ğŸ§  FormÃ¼lÃ¼n MantÄ±ÄŸÄ±:**
    
    Bu formÃ¼l **Log Loss'u akÄ±llÄ±ca modifiye eder** zor Ã¶rneklere odaklanmak iÃ§in:
    
    - **pt**: DoÄŸru sÄ±nÄ±f iÃ§in tahmin edilen probability
    - **Î± (alpha)**: SÄ±nÄ±f dengeleme faktÃ¶rÃ¼ (0.25 tipik deÄŸer)
    - **Î³ (gamma)**: Focusing parameter (2.0 tipik deÄŸer)
    - **(1-pt)^Î³**: Modulating factor â†’ **Bu bÃ¼yÃ¼ burada!**
    
    **ğŸ’¡ (1-pt)^Î³ BÃ¼yÃ¼sÃ¼:**
    """)
    
    st.latex(r'''
    p_t = 0.9 \text{ (kolay Ã¶rnek)} \rightarrow (1-0.9)^2 = 0.01 \rightarrow \text{Loss 100'de 1'ine iner!}
    ''')
    
    st.latex(r'''
    p_t = 0.6 \text{ (orta Ã¶rnek)} \rightarrow (1-0.6)^2 = 0.16 \rightarrow \text{Loss 6'da 1'ine iner}
    ''')
    
    st.latex(r'''
    p_t = 0.2 \text{ (zor Ã¶rnek)} \rightarrow (1-0.2)^2 = 0.64 \rightarrow \text{Loss neredeyse aynÄ± kalÄ±r}
    ''')
    
    st.markdown("""
    
    **Kolay Ã¶rnekler ihmal edilir, zor Ã¶rneklere odaklanÄ±lÄ±r!**
    """)
    
    st.markdown("""
    <div style="background: #e8f5e8; padding: 1rem; border-radius: 8px; border-left: 4px solid #4CAF50;">
    <strong>ğŸ“š TarihÃ§e:</strong> Tsung-Yi Lin ve ekibi tarafÄ±ndan 2017'de **RetinaNet** paper'Ä±nda tanÄ±tÄ±ldÄ±. 
    Object detection'da **class imbalance** problemi vardÄ±: background pixels Ã§ok, object pixels az. 
    Model kolay background'larÄ± Ã¶ÄŸrenip object'leri ihmal ediyordu. Focal Loss bunu Ã§Ã¶zdÃ¼ ve 
    one-stage detector'larÄ± two-stage kadar baÅŸarÄ±lÄ± hale getirdi!
    </div>
    """, unsafe_allow_html=True)
    
    # Interactive parameter exploration
    st.markdown("### ğŸ® Parameter Etkisini KeÅŸfet")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Parametreleri Ayarla:**")
        alpha = st.slider("Alpha (Î±) - SÄ±nÄ±f AÄŸÄ±rlÄ±ÄŸÄ±", 0.1, 2.0, 1.0, 0.1)
        gamma = st.slider("Gamma (Î³) - Odaklanma GÃ¼cÃ¼", 0.0, 5.0, 2.0, 0.5)
        
        st.markdown("**Test Senaryosu:**")
        true_class = st.selectbox("GerÃ§ek sÄ±nÄ±f", [0, 1], index=1, key="focal_true")
        predicted_prob = st.slider("Tahmin olasÄ±lÄ±ÄŸÄ±", 0.01, 0.99, 0.7, key="focal_prob")
    
    with col2:
        # Calculate focal loss vs standard log loss
        epsilon = 1e-15
        
        if true_class == 1:
            p = max(predicted_prob, epsilon)
        else:
            p = max(1 - predicted_prob, epsilon)
        
        # Standard log loss
        log_loss_val = -np.log(p)
        
        # Focal loss
        focal_loss_val = -alpha * ((1 - p) ** gamma) * np.log(p)
        
        st.markdown("**ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma:**")
        st.metric("Standard Log Loss", f"{log_loss_val:.3f}")
        st.metric("Focal Loss", f"{focal_loss_val:.3f}")
        st.metric("Focal/Log Ratio", f"{focal_loss_val/log_loss_val:.2f}")
        
        # Difficulty assessment
        if p > 0.8:
            difficulty = "ğŸŸ¢ Kolay Ã–rnek"
        elif p > 0.6:
            difficulty = "ğŸŸ¡ Orta Ã–rnek"
        else:
            difficulty = "ğŸ”´ Zor Ã–rnek"
        
        st.markdown(f"**Ã–rnek ZorluÄŸu:** {difficulty}")
    
    # Comparative visualization
    st.markdown("### ğŸ“Š Focal Loss vs Log Loss KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    
    prob_range = np.linspace(0.01, 0.99, 100)
    log_losses = -np.log(prob_range)
    focal_losses = -alpha * ((1 - prob_range) ** gamma) * np.log(prob_range)
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=prob_range, y=log_losses, 
                           name='Standard Log Loss', 
                           line=dict(color='blue')))
    fig.add_trace(go.Scatter(x=prob_range, y=focal_losses, 
                           name=f'Focal Loss (Î±={alpha}, Î³={gamma})', 
                           line=dict(color='red')))
    
    # Add current prediction point
    current_p = predicted_prob if true_class == 1 else (1 - predicted_prob)
    current_log = -np.log(max(current_p, epsilon))
    current_focal = -alpha * ((1 - current_p) ** gamma) * np.log(max(current_p, epsilon))
    
    fig.add_trace(go.Scatter(x=[current_p], y=[current_log],
                           mode='markers', marker=dict(size=12, color='blue'),
                           name='Sizin Log Loss'))
    fig.add_trace(go.Scatter(x=[current_p], y=[current_focal],
                           mode='markers', marker=dict(size=12, color='red'),
                           name='Sizin Focal Loss'))
    
    fig.update_layout(
        title="Loss Comparison: Easy vs Hard Examples",
        xaxis_title="Predicted Probability (for True Class)",
        yaxis_title="Loss Value",
        annotations=[
            dict(x=0.9, y=0.5, text="Kolay Ã–rnekler<br>(YÃ¼ksek p)", 
                 showarrow=False, bgcolor="lightgreen", opacity=0.7),
            dict(x=0.1, y=3, text="Zor Ã–rnekler<br>(DÃ¼ÅŸÃ¼k p)", 
                 showarrow=False, bgcolor="lightcoral", opacity=0.7)
        ]
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Imbalanced dataset demo
    st.markdown("### âš–ï¸ Imbalanced Dataset Senaryosu")
    
    st.markdown("""
    <div style="background: #f0f8ff; padding: 1rem; border-radius: 8px; border-left: 4px solid #4169E1;">
    <strong>ğŸ¯ Senaryo:</strong> Bir hastanede kanser tespiti yapan AI modeli var.<br>
    â€¢ <strong>Ã‡oÄŸunluk sÄ±nÄ±fÄ±</strong>: SaÄŸlÄ±klÄ± hastalar (tahmin etmesi kolay)<br>
    â€¢ <strong>AzÄ±nlÄ±k sÄ±nÄ±fÄ±</strong>: Kanserli hastalar (tahmin etmesi zor ve kritik!)
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("<strong>ğŸ¥ Dataset Kompozisyonu:</strong>", unsafe_allow_html=True)
        majority_class_size = st.slider("SaÄŸlÄ±klÄ± hastalar (kolay Ã¶rnekler)", 500, 2000, 1000)
        minority_class_size = st.slider("Kanserli hastalar (zor Ã¶rnekler)", 10, 200, 50)
        
        # Simulate some predictions
        np.random.seed(42)
        # Majority class predictions (easier to predict)
        maj_probs = np.random.beta(8, 2, majority_class_size)  # High confidence
        # Minority class predictions (harder to predict)  
        min_probs = np.random.beta(3, 3, minority_class_size)  # Lower confidence
        
        # Calculate losses
        maj_log_losses = -np.log(np.clip(maj_probs, epsilon, 1-epsilon))
        min_log_losses = -np.log(np.clip(min_probs, epsilon, 1-epsilon))
        
        maj_focal_losses = -alpha * ((1 - maj_probs) ** gamma) * np.log(np.clip(maj_probs, epsilon, 1-epsilon))
        min_focal_losses = -alpha * ((1 - min_probs) ** gamma) * np.log(np.clip(min_probs, epsilon, 1-epsilon))
        
    with col2:
        # Show average losses
        avg_maj_log = np.mean(maj_log_losses)
        avg_min_log = np.mean(min_log_losses)
        avg_maj_focal = np.mean(maj_focal_losses)
        avg_min_focal = np.mean(min_focal_losses)
        
        st.markdown("<strong>ğŸ“Š Ortalama Loss DeÄŸerleri (Model Ne Kadar ZorlanÄ±yor?):</strong>", unsafe_allow_html=True)
        
        loss_comparison_df = pd.DataFrame({
            'Loss TÃ¼rÃ¼': ['Log Loss', 'Focal Loss'],
            'SaÄŸlÄ±klÄ± (Kolay)': [f"{avg_maj_log:.3f}", f"{avg_maj_focal:.3f}"],
            'Kanserli (Zor)': [f"{avg_min_log:.3f}", f"{avg_min_focal:.3f}"]
        })
        
        st.dataframe(loss_comparison_df, use_container_width=True)
        
        st.markdown("""
        <div style="background: #e8f5e8; padding: 0.8rem; border-radius: 6px;">
        <strong>ğŸ“– Tablo NasÄ±l Okunur:</strong><br>
        â€¢ <strong>DÃ¼ÅŸÃ¼k sayÄ±</strong>: Model bu grubu kolay tahmin ediyor<br>
        â€¢ <strong>YÃ¼ksek sayÄ±</strong>: Model bu grubu zor tahmin ediyor<br>
        â€¢ Focal Loss kolay Ã¶rnekleri "ihmal ediyor" (sayÄ± dÃ¼ÅŸÃ¼yor)
        </div>
        """, unsafe_allow_html=True)
        
        # Show the focus shift with better explanation
        total_log_loss = (majority_class_size * avg_maj_log + minority_class_size * avg_min_log) / (majority_class_size + minority_class_size)
        total_focal_loss = (majority_class_size * avg_maj_focal + minority_class_size * avg_min_focal) / (majority_class_size + minority_class_size)
        
        st.markdown("<strong>ğŸ¯ Genel Performans Analizi:</strong>", unsafe_allow_html=True)
        
        col_a, col_b = st.columns(2)
        with col_a:
            st.metric("Toplam Log Loss", f"{total_log_loss:.3f}", help="TÃ¼m Ã¶rneklerin ortalama loss'u")
        with col_b:
            st.metric("Toplam Focal Loss", f"{total_focal_loss:.3f}", help="Focal loss ile ortalama loss")
        
        # Ratio showing focus shift
        focus_ratio = (avg_min_focal / avg_maj_focal) / (avg_min_log / avg_maj_log)
        st.metric("Odaklanma GÃ¼cÃ¼", f"{focus_ratio:.2f}x", 
                 help="Focal Loss'un zor Ã¶rneklere ne kadar daha fazla odaklandÄ±ÄŸÄ±")
        
        if focus_ratio > 1.5:
            st.success("âœ… Focal Loss zor Ã¶rneklere gÃ¼Ã§lÃ¼ ÅŸekilde odaklanÄ±yor!")
        elif focus_ratio > 1.2:
            st.info("â„¹ï¸ Focal Loss orta seviyede odaklanma saÄŸlÄ±yor")
        else:
            st.warning("âš ï¸ Focal Loss Ã§ok az odaklanma saÄŸlÄ±yor")
    
    # Distribution visualization with clear explanation
    st.markdown("### ğŸ“ˆ Loss DaÄŸÄ±lÄ±mlarÄ± Analizi")
    
    st.markdown("""
    <div style="background: #fff3e0; padding: 1rem; border-radius: 8px; border-left: 4px solid #FF9800;">
    <strong>ğŸ“Š Bu Grafik Neyi GÃ¶steriyor?</strong><br>
    Her Ã§ubuk, o loss deÄŸerinde kaÃ§ tane hasta olduÄŸunu gÃ¶steriyor.<br>
    â€¢ <strong>Sola yakÄ±n</strong> (dÃ¼ÅŸÃ¼k loss): Model emin, doÄŸru tahmin<br>
    â€¢ <strong>SaÄŸa yakÄ±n</strong> (yÃ¼ksek loss): Model kararsÄ±z, yanlÄ±ÅŸ tahmin<br>
    â€¢ <strong>Focal Loss'un gÃ¼cÃ¼</strong>: Kolay Ã¶rnekleri sola itiyor (ihmal ediyor)
    </div>
    """, unsafe_allow_html=True)
    
    # Create side-by-side comparison
    col1, col2 = st.columns(2)
    
    with col1:
        fig1 = go.Figure()
        fig1.add_trace(go.Histogram(x=maj_log_losses, name='SaÄŸlÄ±klÄ± (Kolay)', 
                                   opacity=0.7, nbinsx=20, marker_color='lightblue'))
        fig1.add_trace(go.Histogram(x=min_log_losses, name='Kanserli (Zor)', 
                                   opacity=0.7, nbinsx=20, marker_color='lightcoral'))
        
        fig1.update_layout(title="ğŸ“Š Log Loss DaÄŸÄ±lÄ±mÄ±", 
                          xaxis_title="Loss DeÄŸeri", 
                          yaxis_title="Hasta SayÄ±sÄ±",
                          barmode='overlay',
                          height=400)
        st.plotly_chart(fig1, use_container_width=True)
        
        st.markdown("""
        <strong>ğŸ” Log Loss'ta Ne GÃ¶rÃ¼yoruz?</strong><br>
        â€¢ Mavi (saÄŸlÄ±klÄ±): DÃ¼ÅŸÃ¼k loss, kolay tahmin<br>
        â€¢ KÄ±rmÄ±zÄ± (kanserli): YÃ¼ksek loss, zor tahmin<br>
        â€¢ Model her iki gruba da eÅŸit Ã¶nem veriyor
        """, unsafe_allow_html=True)
    
    with col2:
        fig2 = go.Figure()
        fig2.add_trace(go.Histogram(x=maj_focal_losses, name='SaÄŸlÄ±klÄ± (Kolay)', 
                                   opacity=0.7, nbinsx=20, marker_color='lightgreen'))
        fig2.add_trace(go.Histogram(x=min_focal_losses, name='Kanserli (Zor)', 
                                   opacity=0.7, nbinsx=20, marker_color='orange'))
        
        fig2.update_layout(title="ğŸ¯ Focal Loss DaÄŸÄ±lÄ±mÄ±", 
                          xaxis_title="Loss DeÄŸeri", 
                          yaxis_title="Hasta SayÄ±sÄ±",
                          barmode='overlay',
                          height=400)
        st.plotly_chart(fig2, use_container_width=True)
        
        st.markdown("""
        <strong>ğŸ¯ Focal Loss'ta Ne GÃ¶rÃ¼yoruz?</strong><br>
        â€¢ YeÅŸil (saÄŸlÄ±klÄ±): Ã‡ok dÃ¼ÅŸÃ¼k loss, ihmal ediliyor<br>
        â€¢ Turuncu (kanserli): Loss deÄŸiÅŸmedi, odaklanÄ±lÄ±yor<br>
        â€¢ Model zor Ã¶rneklere odaklanmaya baÅŸladÄ±!
        """, unsafe_allow_html=True)
    
    # Summary comparison
    st.markdown("### ğŸ”¬ KarÅŸÄ±laÅŸtÄ±rma Ã–zeti")
    
    insight_col1, insight_col2, insight_col3 = st.columns(3)
    
    with insight_col1:
        kolay_azalma = ((avg_maj_log - avg_maj_focal) / avg_maj_log) * 100
        st.metric("Kolay Ã–rnekler", f"{kolay_azalma:.1f}% azaldÄ±", 
                 delta=f"Loss {avg_maj_log:.3f}â†’{avg_maj_focal:.3f}")
    
    with insight_col2:
        zor_azalma = ((avg_min_log - avg_min_focal) / avg_min_log) * 100
        st.metric("Zor Ã–rnekler", f"{zor_azalma:.1f}% azaldÄ±", 
                 delta=f"Loss {avg_min_log:.3f}â†’{avg_min_focal:.3f}")
    
    with insight_col3:
        if kolay_azalma > zor_azalma * 2:
            st.success("âœ… MÃ¼kemmel! Focal Loss kolay Ã¶rnekleri daha Ã§ok azalttÄ±")
        elif kolay_azalma > zor_azalma:
            st.info("â„¹ï¸ Ä°yi! Kolay Ã¶rnekler daha fazla azaldÄ±")
        else:
            st.warning("âš ï¸ Focal Loss beklenen etkiyi gÃ¶stermiyor")
    
    st.markdown("""
    <div class="fun-fact">
    <h3>ğŸŒŸ Focal Loss'un SÃ¼per GÃ¼Ã§leri</h3>
    <p>â€¢ Imbalanced dataset'lerde mÃ¼kemmel<br>
    â€¢ Zor Ã¶rneklere otomatik odaklanma<br>
    â€¢ Object detection'da devrim yarattÄ±<br>
    â€¢ RetinaNet gibi modern modellerde kullanÄ±lÄ±r<br>
    â€¢ Hyperparameter tuning ile Ã§ok esnek</p>
    </div>
    """, unsafe_allow_html=True)

def main():
    """Main application"""
    
    # Sidebar navigation
    st.sidebar.title("ğŸ¯ Navigation")
    page = st.sidebar.selectbox(
        "Bir metrik seÃ§in:",
        [
            "ğŸ  Ana Sayfa",
            "âš–ï¸ Balanced Accuracy", 
            "ğŸ”— Matthews Correlation Coefficient",
            "ğŸ¤ Cohen's Kappa",
            "âš–ï¸ Quadratic Weighted Kappa",
            "ğŸ“‰ Log Loss",
            "ğŸ” Focal Loss"
        ]
    )
    
    # Page routing
    if page == "ğŸ  Ana Sayfa":
        homepage()
    elif page == "âš–ï¸ Balanced Accuracy":
        balanced_accuracy_page()
    elif page == "ğŸ”— Matthews Correlation Coefficient":
        matthews_correlation_page()
    elif page == "ğŸ¤ Cohen's Kappa":
        cohens_kappa_page()
    elif page == "âš–ï¸ Quadratic Weighted Kappa":
        quadratic_weighted_kappa_page()
    elif page == "ğŸ“‰ Log Loss":
        log_loss_page()
    elif page == "ğŸ” Focal Loss":
        focal_loss_page()
    
    # Footer
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style='text-align: center; color: #666;'>
    <p>ğŸ“ ML Metrics Akademisi</p>
    <p>EÄŸlenceli Ã¶ÄŸrenme deneyimi</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 